{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "We'll build a **training loop** to perform multiple optimizations in a row, attempting to decrease the loss as much as possible.\n",
    "\n",
    "Only 1 additional line: `optimizer.zero_grad()`\n",
    "This resets the gradients for each iteration.\n",
    "\n",
    "**Epochs**: iterations of the training loop.\n",
    "\n",
    "**Batch size**: number of samples processed in each iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "apartments_df = pd.read_csv(\"streeteasy.csv\")\n",
    "\n",
    "numerical_features = ['bedrooms', 'bathrooms', 'size_sqft', 'min_to_subway', 'floor', 'building_age_yrs',\n",
    "                      'no_fee', 'has_roofdeck', 'has_washer_dryer', 'has_doorman', 'has_elevator', 'has_dishwasher',\n",
    "                      'has_patio', 'has_gym']\n",
    "\n",
    "# create tensor of input features\n",
    "X = torch.tensor(apartments_df[numerical_features].values, dtype=torch.float)\n",
    "# create tensor of targets\n",
    "y = torch.tensor(apartments_df['rent'].values, dtype=torch.float).view(-1,1)\n",
    "\n",
    "# define the model using nn.Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(14, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 1)\n",
    ")\n",
    "\n",
    "# MSE loss function + optimizer\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    predictions = model(X) # forward pass\n",
    "    MSE = loss(predictions,y) # compute loss\n",
    "    MSE.backward() # compute gradients\n",
    "    optimizer.step() # update weights and biases\n",
    "    optimizer.zero_grad() # reset the gradients for the next iteration\n",
    "\n",
    "    # keep track of the loss during training\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], MSE Loss: {MSE.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to print the loss value regularly. Here's one example of doing it every 100 epochs:\n",
    "\n",
    "```python\n",
    "    # keep track of the loss values during training\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], MSE Loss: {MSE.item()}')\n",
    "```\n",
    "\n",
    "**Note**: `MSE.item()` is used to get the loss value as a Python number"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
