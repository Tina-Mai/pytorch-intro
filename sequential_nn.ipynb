{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Neural Network\n",
    "\n",
    "PyTorch `Sequential` class is a container for linear layers.\n",
    "\n",
    "### Example:\n",
    "![Sequential neural network](images/sequential.svg)\n",
    "\n",
    "This network has\n",
    "- input layer: 2 nodes\n",
    "- 1 hidden layer: 3 nodes with ReLU activation\n",
    "- output layer: 1 node\n",
    "\n",
    "Here’s how we’d build the example network:\n",
    "\n",
    "```python\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2,3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3,1)\n",
    ")\n",
    "```\n",
    "\n",
    "1. `nn.Linear(2,3)` connects the 2 input nodes to the 3 hidden nodes using our standard weights-and-bias linear calculation\n",
    "2. `nn.ReLU()` applies the ReLU activation function to that linear computation\n",
    "3. `nn.Linear(3,1)` connects the ReLU output from the 3 hidden nodes to the 1 output node (again, using our usual linear calculation)\n",
    "\n",
    "**Note**: the connections between layers **must be properly aligned**. Once we defined `nn.Linear(2,3)` as the first layer, the next `nn.Linear()` must start with 3 nodes.\n",
    "\n",
    "## Running Feedforward\n",
    "\n",
    "To run through the feedforward process with our `Sequential` model, we need to pass a tensor as input to `model`.\n",
    "\n",
    "Typically our input tensors will be two-dimensional, consisting of:\n",
    "- **rows**: individual examples (ex: each row is an apartment)\n",
    "- **columns**: individual features (ex: each column is an apartment property, like size)\n",
    "Statisticians call examples **observations**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "The 2 input nodes in our model correspond to building age and number of bedrooms. Let's create an input tensor with a couple apartments and run the feedforward process.\n",
    "\n",
    "**Note**: Typically, input tensors are stored in a variable named `X` (this is a convention from mathematics that main ML engineers follow). The input tensor is usually capitalized (`X` and not `x`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2,3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3,1)\n",
    ")\n",
    "\n",
    "# create apartment data\n",
    "apts = np.array(\n",
    "    [[100,3], # 100 years old, 3 bedrooms\n",
    "    [50,4]]) # 50 years old, 4 bedrooms\n",
    "\n",
    "# convert to a tensor\n",
    "X = torch.tensor(apts, dtype=torch.float)\n",
    "\n",
    "# run feedforward\n",
    "output = model(X)\n",
    "\n",
    "# output: the result of a feedforward through the network layers\n",
    "print(output)\n",
    "#>>>tensor([[-23.0715],\n",
    "#        [-11.8710]], grad_fn=<AddmmBackward0>)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
