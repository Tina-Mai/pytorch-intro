{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Optimizer\n",
    "\n",
    "The **loss function** tells us how poorly our model is doing. The **optimizer** is the tool that helps us improve the model's performance by adjusting the weights and biases.\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "Uses calculus to determine the gradients of the loss function. These gradients are the direction signs that indicate which way to adjust the weights and biases in order to decrease the loss function.\n",
    "\n",
    "### Learning Rate\n",
    "\n",
    "**Learning rate**: how far to move at each step\n",
    "- Too low: slow convergence\n",
    "- Too high: overshoot the minimum\n",
    "\n",
    "Learning rate is a classic example of **hyperparameters**: values tuned and tweaked by ML engineers during training to improve performance of the model\n",
    "**Hyperparameter tuning**: the process of adjusting hyperparameters in search of the best model performance\n",
    "\n",
    "\n",
    "### PyTorch Optimizer\n",
    "A popular optimizer in PyTorch, **Adam**, uses gradient descent with a few extra bells and whistles (like adjusting the learning rate dynamically during training)\n",
    "\n",
    "- `model.parameters()` tells Adam what our current weights and biases are\n",
    "- `lr=0.01` tells Adam to set the learning rate to 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply Adam to a neural network, we need to perform the:\n",
    "\n",
    "1. **backwards pass**: calculate the gradients of the loss function (these determine the “downward” direction)\n",
    "2. **step**: use the gradients to update the weights and biases\n",
    "\n",
    "**Note**: `backward` is applied to the computed loss, not the loss function. This is why the output of the loss function includes the parameter `grad_fn=<MseLossBackward0>`. This parameter is the function used to perform the backwards pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss \n",
    "MSE = loss(predictions,y)\n",
    "# backward pass to determine \"downward\" direction\n",
    "MSE.backward()\n",
    "# apply the optimizer to update weights and biases\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "\n",
    "# create neural network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3,16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16,8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8,4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4,1)\n",
    ")\n",
    "\n",
    "# import the data\n",
    "apartments_df = pd.read_csv(\"streeteasy.csv\")\n",
    "numerical_features = ['bedrooms', 'bathrooms', 'size_sqft']\n",
    "X = torch.tensor(apartments_df[numerical_features].values, dtype=torch.float)\n",
    "y = torch.tensor(apartments_df['rent'].values,dtype=torch.float)\n",
    "\n",
    "# forward pass\n",
    "predictions = model(X)\n",
    "\n",
    "# define the loss function and compute loss\n",
    "loss = nn.MSELoss()\n",
    "MSE = loss(predictions,y)\n",
    "print('Initial loss is ' + str(MSE))\n",
    "\n",
    "# create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# use the loss to perform the backwards pass\n",
    "MSE.backward()\n",
    "\n",
    "# use optimizer to update the weights and biases\n",
    "optimizer.step()\n",
    "\n",
    "# feed the data through the updated model and compute the new loss\n",
    "predictions = model(X)\n",
    "MSE = loss(predictions,y)\n",
    "print('After optimization, loss is ' + str(MSE))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
